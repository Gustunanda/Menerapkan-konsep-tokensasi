# -*- coding: utf-8 -*-
"""Tugas Tokenize.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WduKAiuTBiDn1y_CKwC84MyKw5fLIFD6
"""

import requests 
import string
import re

from bs4 import BeautifulSoup
import nltk
from nltk.corpus import stopwords

!pip install Sastrawi
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

web = requests.get ('https://id.wikipedia.org/wiki/Komputer').text 
soup = BeautifulSoup (web)
for s in soup (['script', 'style']):
  s.decompose ()
teks = ' '.join (soup.stripped_strings)
print (teks)

teks = teks.lower()
teks = re.sub(r"\d+","",teks)
teks = teks.translate(str.maketrans("","",string.punctuation))
teks = teks.strip()

factory = StemmerFactory()
stemmer = factory.create_stemmer()
output = stemmer.stem(teks)
print(output)

tokens = [t for t in output.split()]
print (tokens)

nltk.download()
clean_tokens = tokens[:]
for token in tokens:
  if token in stopwords.words('indonesian'):
    clean_tokens.remove(token)

freq = nltk.FreqDist(clean_tokens)
for key,val in freq.items():
  print(str(key) + ":" + str(val))

freq.plot(30)